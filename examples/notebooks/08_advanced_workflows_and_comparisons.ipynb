{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Workflows and Comprehensive Comparisons\n",
    "\n",
    "This notebook demonstrates advanced workflows and comprehensive comparisons of all available detectors and scorers in Anomsmith.\n",
    "\n",
    "We'll cover:\n",
    "1. Comprehensive detector/scorer comparison\n",
    "2. Ensemble approaches\n",
    "3. Real-world workflow patterns\n",
    "4. Best practices and recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotsmith import plot_timeseries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from anomsmith import (\n",
    "    detect_anomalies, \n",
    "    sweep_thresholds, \n",
    "    backtest_detector,\n",
    "    ThresholdRule\n",
    ")\n",
    "from anomsmith.primitives.scorers.robust_zscore import RobustZScoreScorer\n",
    "from anomsmith.primitives.scorers.statistical import ZScoreScorer, IQRScorer\n",
    "from anomsmith.primitives.detectors.ml import (\n",
    "    IsolationForestDetector,\n",
    "    LOFDetector,\n",
    "    RobustCovarianceDetector\n",
    ")\n",
    "from anomsmith.primitives.detectors.pca import PCADetector\n",
    "from anomsmith.primitives.detectors.change_point import ChangePointDetector\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Comprehensive Test Data\n",
    "\n",
    "We'll create complex data that tests various anomaly types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_data(n: int = 300, contamination: float = 0.1, seed: int = 42):\n",
    "    \"\"\"Create comprehensive test data with various anomaly types.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Base series with trend and seasonality\n",
    "    t = np.arange(n)\n",
    "    trend = 0.01 * t\n",
    "    seasonal = 2 * np.sin(2 * np.pi * t / 50)\n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    y = trend + seasonal + noise\n",
    "    \n",
    "    # Inject different types of anomalies\n",
    "    n_anomalies = int(n * contamination)\n",
    "    anomaly_indices = np.random.choice(n, n_anomalies, replace=False)\n",
    "    \n",
    "    for idx in anomaly_indices:\n",
    "        anomaly_type = np.random.choice(['spike', 'level_shift', 'contextual'])\n",
    "        if anomaly_type == 'spike':\n",
    "            y[idx] += np.random.choice([-1, 1]) * np.random.uniform(4, 8)\n",
    "        elif anomaly_type == 'level_shift':\n",
    "            # Create a small level shift\n",
    "            shift_size = np.random.uniform(2, 4)\n",
    "            y[idx:min(idx+5, n)] += np.random.choice([-1, 1]) * shift_size\n",
    "        else:\n",
    "            # Contextual anomaly\n",
    "            y[idx] += np.random.choice([-1, 1]) * np.random.uniform(1.5, 3)\n",
    "    \n",
    "    # Create ground truth labels\n",
    "    labels = pd.Series(np.zeros(n), index=pd.date_range(\"2020-01-01\", periods=n, freq=\"D\"))\n",
    "    labels.iloc[anomaly_indices] = 1\n",
    "    \n",
    "    index = pd.date_range(\"2020-01-01\", periods=n, freq=\"D\")\n",
    "    y_series = pd.Series(y, index=index)\n",
    "    \n",
    "    return y_series, labels, anomaly_indices\n",
    "\n",
    "y, labels, true_anomaly_indices = create_comprehensive_data(n=300, contamination=0.1)\n",
    "print(f\"Created time series with {len(y)} points\")\n",
    "print(f\"True anomalies: {labels.sum()}\")\n",
    "print(f\"Anomaly rate: {labels.mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Detector Comparison\n",
    "\n",
    "Let's test all available detectors and scorers on the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all detectors and scorers\n",
    "threshold_rule = ThresholdRule(method=\"quantile\", value=0.9, quantile=0.9)\n",
    "\n",
    "detectors_scorers = {\n",
    "    'RobustZScore': RobustZScoreScorer(epsilon=1e-8),\n",
    "    'ZScore': ZScoreScorer(),\n",
    "    'IQR': IQRScorer(),\n",
    "    'IsolationForest': IsolationForestDetector(contamination=0.1, random_state=42),\n",
    "    'LOF': LOFDetector(n_neighbors=20, contamination=0.1),\n",
    "    'RobustCovariance': RobustCovarianceDetector(contamination=0.1, random_state=42),\n",
    "    'ChangePoint': ChangePointDetector(window_size=10, threshold_multiplier=3.0),\n",
    "}\n",
    "\n",
    "# Fit and detect with all\n",
    "results_all = {}\n",
    "for name, detector_scorer in detectors_scorers.items():\n",
    "    detector_scorer.fit(y.values)\n",
    "    results_all[name] = detect_anomalies(y, detector_scorer, threshold_rule)\n",
    "\n",
    "# Calculate metrics for each\n",
    "comparison_metrics = {}\n",
    "for name, result in results_all.items():\n",
    "    if labels is not None:\n",
    "        aligned_labels = labels.reindex(result.index, fill_value=0).values\n",
    "        aligned_labels = (aligned_labels != 0).astype(int)\n",
    "        pred_labels = result['flag'].values\n",
    "        \n",
    "        from anomsmith.workflows.eval.metrics import (\n",
    "            compute_precision, compute_recall, compute_f1\n",
    "        )\n",
    "        \n",
    "        precision = compute_precision(aligned_labels, pred_labels)\n",
    "        recall = compute_recall(aligned_labels, pred_labels)\n",
    "        f1 = compute_f1(aligned_labels, pred_labels)\n",
    "    else:\n",
    "        precision = recall = f1 = np.nan\n",
    "    \n",
    "    comparison_metrics[name] = {\n",
    "        'Anomalies Detected': result['flag'].sum(),\n",
    "        'Anomaly Rate': result['flag'].mean(),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'Mean Score': result['score'].mean(),\n",
    "        'Std Score': result['score'].std()\n",
    "    }\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_metrics).T\n",
    "print(\"Comprehensive Detector/Scorer Comparison:\")\n",
    "print(comparison_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Precision, Recall, F1 comparison\n",
    "metrics_to_plot = ['Precision', 'Recall', 'F1']\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    values = comparison_df[metric].sort_values(ascending=False)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(values)))\n",
    "    bars = ax.barh(range(len(values)), values.values, color=colors, alpha=0.7)\n",
    "    ax.set_yticks(range(len(values)))\n",
    "    ax.set_yticklabels(values.index)\n",
    "    ax.set_xlabel(metric, fontsize=12)\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, values.values)):\n",
    "        if not np.isnan(val):\n",
    "            ax.text(val, i, f' {val:.3f}', va='center', fontsize=10)\n",
    "\n",
    "# Anomaly detection count\n",
    "ax = axes[1, 1]\n",
    "detected_counts = comparison_df['Anomalies Detected'].sort_values(ascending=False)\n",
    "colors = plt.cm.plasma(np.linspace(0, 1, len(detected_counts)))\n",
    "bars = ax.barh(range(len(detected_counts)), detected_counts.values, color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(detected_counts)))\n",
    "ax.set_yticklabels(detected_counts.index)\n",
    "ax.set_xlabel('Anomalies Detected', fontsize=12)\n",
    "ax.set_title('Detection Count Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.axvline(labels.sum(), color='r', linestyle='--', linewidth=2, \n",
    "          label=f'True Anomalies ({int(labels.sum())})')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Recommendations\n",
    "\n",
    "### When to Use Each Detector/Scorer:\n",
    "\n",
    "1. **Statistical Scorers (ZScore, IQR, RobustZScore)**\n",
    "   - Fast and interpretable\n",
    "   - Good for univariate time series\n",
    "   - RobustZScore is most robust to outliers\n",
    "\n",
    "2. **Machine Learning Detectors (Isolation Forest, LOF, Robust Covariance)**\n",
    "   - Better for complex patterns\n",
    "   - Isolation Forest: Fast, good for high-dimensional data\n",
    "   - LOF: Good for local anomalies\n",
    "   - Robust Covariance: Good for multivariate Gaussian data\n",
    "\n",
    "3. **PCA Detector**\n",
    "   - Excellent for multivariate data\n",
    "   - Captures main patterns in normal data\n",
    "\n",
    "4. **Change Point Detector**\n",
    "   - Best for detecting structural breaks\n",
    "   - Good for regime changes and level shifts\n",
    "\n",
    "### Workflow Recommendations:\n",
    "\n",
    "1. Start with simple statistical scorers\n",
    "2. Use threshold sweeping to find optimal thresholds\n",
    "3. Validate with backtesting\n",
    "4. Consider ensemble approaches for critical applications\n",
    "5. Monitor performance over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this comprehensive notebook, we've:\n",
    "1. Compared all available detectors and scorers\n",
    "2. Evaluated performance using multiple metrics\n",
    "3. Visualized comprehensive comparisons\n",
    "4. Provided best practices and recommendations\n",
    "\n",
    "Key takeaways:\n",
    "- Different detectors excel at different anomaly types\n",
    "- Statistical methods are fast and interpretable\n",
    "- ML methods handle complex patterns better\n",
    "- Always validate with backtesting\n",
    "- Consider your specific use case when choosing detectors\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
