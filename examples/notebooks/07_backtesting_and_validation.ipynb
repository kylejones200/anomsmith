{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting and Model Validation\n",
    "\n",
    "This notebook demonstrates how to use `backtest_detector` to validate anomaly detectors using expanding window splits.\n",
    "\n",
    "Backtesting is crucial for:\n",
    "- Validating detector performance on historical data\n",
    "- Understanding how detectors perform over time\n",
    "- Detecting performance degradation\n",
    "- Comparing different detectors fairly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotsmith import plot_timeseries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from anomsmith import backtest_detector, detect_anomalies, ThresholdRule\n",
    "from anomsmith.primitives.scorers.robust_zscore import RobustZScoreScorer\n",
    "from anomsmith.primitives.detectors.ml import IsolationForestDetector\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Time Series Data for Backtesting\n",
    "\n",
    "We'll create a longer time series to demonstrate expanding window backtesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_backtest_data(n: int = 500, contamination: float = 0.08, seed: int = 42):\n",
    "    \"\"\"Create time series data for backtesting.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Base series with trend\n",
    "    t = np.arange(n)\n",
    "    trend = 0.005 * t\n",
    "    seasonal = 1.5 * np.sin(2 * np.pi * t / 100)\n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    y = trend + seasonal + noise\n",
    "    \n",
    "    # Inject anomalies\n",
    "    n_anomalies = int(n * contamination)\n",
    "    anomaly_indices = np.random.choice(n, n_anomalies, replace=False)\n",
    "    y[anomaly_indices] += np.random.choice([-1, 1], n_anomalies) * np.random.uniform(4, 7, n_anomalies)\n",
    "    \n",
    "    # Create ground truth labels\n",
    "    labels = pd.Series(np.zeros(n), index=pd.date_range(\"2020-01-01\", periods=n, freq=\"D\"))\n",
    "    labels.iloc[anomaly_indices] = 1\n",
    "    \n",
    "    index = pd.date_range(\"2020-01-01\", periods=n, freq=\"D\")\n",
    "    y_series = pd.Series(y, index=index)\n",
    "    \n",
    "    return y_series, labels\n",
    "\n",
    "y, labels = create_backtest_data(n=500, contamination=0.08)\n",
    "print(f\"Created time series with {len(y)} points\")\n",
    "print(f\"True anomalies: {labels.sum()}\")\n",
    "print(f\"Anomaly rate: {labels.mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(y.index, y.values, 'b-', linewidth=1.5, alpha=0.7, label='Time Series')\n",
    "anomaly_indices = labels[labels == 1].index\n",
    "ax.scatter(anomaly_indices, y.loc[anomaly_indices], \n",
    "          color='red', s=100, marker='x', linewidths=2, \n",
    "          label=f'True Anomalies ({len(anomaly_indices)})', zorder=5)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_title('Time Series for Backtesting', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Backtests\n",
    "\n",
    "Let's run backtests with different detectors and compare their performance across folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold rule\n",
    "threshold_rule = ThresholdRule(method=\"quantile\", value=0.9, quantile=0.9)\n",
    "\n",
    "# Backtest with RobustZScoreScorer\n",
    "scorer = RobustZScoreScorer(epsilon=1e-8)\n",
    "backtest_results_scorer = backtest_detector(\n",
    "    y, scorer, threshold_rule, \n",
    "    labels=labels, \n",
    "    n_splits=5, \n",
    "    min_train_size=50\n",
    ")\n",
    "\n",
    "print(\"Backtest Results (RobustZScoreScorer):\")\n",
    "print(backtest_results_scorer)\n",
    "print(f\"\\nAverage F1: {backtest_results_scorer['f1'].mean():.4f}\")\n",
    "print(f\"Average Precision: {backtest_results_scorer['precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {backtest_results_scorer['recall'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest with IsolationForestDetector\n",
    "detector = IsolationForestDetector(contamination=0.1, random_state=42)\n",
    "backtest_results_detector = backtest_detector(\n",
    "    y, detector, threshold_rule,\n",
    "    labels=labels,\n",
    "    n_splits=5,\n",
    "    min_train_size=50\n",
    ")\n",
    "\n",
    "print(\"Backtest Results (IsolationForestDetector):\")\n",
    "print(backtest_results_detector)\n",
    "print(f\"\\nAverage F1: {backtest_results_detector['f1'].mean():.4f}\")\n",
    "print(f\"Average Precision: {backtest_results_detector['precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {backtest_results_detector['recall'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize backtest results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = ['precision', 'recall', 'f1', 'avg_run_length']\n",
    "titles = ['Precision', 'Recall', 'F1 Score', 'Average Run Length']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.plot(backtest_results_scorer['fold'], backtest_results_scorer[metric], \n",
    "           'b-o', linewidth=2, markersize=8, label='RobustZScore', alpha=0.7)\n",
    "    ax.plot(backtest_results_detector['fold'], backtest_results_detector[metric], \n",
    "           'g-s', linewidth=2, markersize=8, label='IsolationForest', alpha=0.7)\n",
    "    ax.set_xlabel('Fold', fontsize=12)\n",
    "    ax.set_ylabel(title, fontsize=12)\n",
    "    ax.set_title(f'{title} Across Folds', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xticks(backtest_results_scorer['fold'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored:\n",
    "1. **backtest_detector**: Running backtests with expanding windows\n",
    "2. **Performance across folds**: Understanding how detectors perform over time\n",
    "3. **Comparing detectors**: Fair comparison using the same backtest setup\n",
    "\n",
    "Key takeaways:\n",
    "- Backtesting validates detector performance on historical data\n",
    "- Expanding windows simulate real-world deployment scenarios\n",
    "- Performance metrics across folds help identify stability issues\n",
    "- Average run length helps understand anomaly segment characteristics\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
